{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e33c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from snac import SNAC\n",
    "import soundfile as sf\n",
    "from datetime import datetime\n",
    "from IPython.display import Audio\n",
    "\n",
    "CODE_START_TOKEN_ID = 128257\n",
    "CODE_END_TOKEN_ID = 128258\n",
    "CODE_TOKEN_OFFSET = 128266\n",
    "SNAC_MIN_ID = 128266\n",
    "SNAC_MAX_ID = 156937\n",
    "SNAC_TOKENS_PER_FRAME = 7\n",
    "\n",
    "SOH_ID = 128259\n",
    "EOH_ID = 128260\n",
    "SOA_ID = 128261\n",
    "BOS_ID = 128000\n",
    "TEXT_EOT_ID = 128009\n",
    "\n",
    "\n",
    "def build_prompt(tokenizer, description: str, text: str) -> str:\n",
    "    \"\"\"Build formatted prompt for Maya1.\"\"\"\n",
    "    soh_token = tokenizer.decode([SOH_ID])\n",
    "    eoh_token = tokenizer.decode([EOH_ID])\n",
    "    soa_token = tokenizer.decode([SOA_ID])\n",
    "    sos_token = tokenizer.decode([CODE_START_TOKEN_ID])\n",
    "    eot_token = tokenizer.decode([TEXT_EOT_ID])\n",
    "    bos_token = tokenizer.bos_token\n",
    "    \n",
    "    formatted_text = f'<description=\"{description}\"> {text}'\n",
    "    \n",
    "    prompt = (\n",
    "        soh_token + bos_token + formatted_text + eot_token +\n",
    "        eoh_token + soa_token + sos_token\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def extract_snac_codes(token_ids: list) -> list:\n",
    "    \"\"\"Extract SNAC codes from generated tokens.\"\"\"\n",
    "    try:\n",
    "        eos_idx = token_ids.index(CODE_END_TOKEN_ID)\n",
    "    except ValueError:\n",
    "        eos_idx = len(token_ids)\n",
    "    \n",
    "    snac_codes = [\n",
    "        token_id for token_id in token_ids[:eos_idx]\n",
    "        if SNAC_MIN_ID <= token_id <= SNAC_MAX_ID\n",
    "    ]\n",
    "    \n",
    "    return snac_codes\n",
    "\n",
    "\n",
    "def unpack_snac_from_7(snac_tokens: list) -> list:\n",
    "    \"\"\"Unpack 7-token SNAC frames to 3 hierarchical levels.\"\"\"\n",
    "    if snac_tokens and snac_tokens[-1] == CODE_END_TOKEN_ID:\n",
    "        snac_tokens = snac_tokens[:-1]\n",
    "    \n",
    "    frames = len(snac_tokens) // SNAC_TOKENS_PER_FRAME\n",
    "    snac_tokens = snac_tokens[:frames * SNAC_TOKENS_PER_FRAME]\n",
    "    \n",
    "    if frames == 0:\n",
    "        return [[], [], []]\n",
    "    \n",
    "    l1, l2, l3 = [], [], []\n",
    "    \n",
    "    for i in range(frames):\n",
    "        slots = snac_tokens[i*7:(i+1)*7]\n",
    "        l1.append((slots[0] - CODE_TOKEN_OFFSET) % 4096)\n",
    "        l2.extend([\n",
    "            (slots[1] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[4] - CODE_TOKEN_OFFSET) % 4096,\n",
    "        ])\n",
    "        l3.extend([\n",
    "            (slots[2] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[3] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[5] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[6] - CODE_TOKEN_OFFSET) % 4096,\n",
    "        ])\n",
    "    \n",
    "    return [l1, l2, l3]\n",
    "\n",
    "\n",
    "# Load the best open source voice AI model\n",
    "print(\"Loading Maya1 model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"maya-research/maya1\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"maya-research/maya1\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "print(f\"Model loaded: {len(tokenizer)} tokens in vocabulary\")\n",
    "\n",
    "# Load SNAC audio decoder (24kHz)\n",
    "print(\"Loading SNAC audio decoder...\")\n",
    "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\").eval()\n",
    "if torch.cuda.is_available():\n",
    "    snac_model = snac_model.to(\"cuda\")\n",
    "print(\"SNAC decoder loaded\")\n",
    "\n",
    "def generate_speech(description, text):\n",
    "    print(\"Generating speech...\")\n",
    "    print(f\"Description: {description}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    # Create prompt with proper formatting\n",
    "    prompt = build_prompt(tokenizer, description, text)\n",
    "\n",
    "    # Debug: Show prompt details\n",
    "    print(\"Prompt preview (first 200 chars):\")\n",
    "    print(f\"   {repr(prompt[:200])}\")\n",
    "    print(f\"   Prompt length: {len(prompt)} chars\")\n",
    "\n",
    "    # Generate emotional speech\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    print(f\"   Input token count: {inputs['input_ids'].shape[1]} tokens\")\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=2048,  # Increase to let model finish naturally\n",
    "            min_new_tokens=28,  # At least 4 SNAC frames\n",
    "            temperature=0.4, \n",
    "            top_p=0.9, \n",
    "            repetition_penalty=1.1,  # Prevent loops\n",
    "            do_sample=True,\n",
    "            eos_token_id=CODE_END_TOKEN_ID,  # Stop at end of speech token\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    # Extract generated tokens (everything after the input prompt)\n",
    "    generated_ids = outputs[0, inputs['input_ids'].shape[1]:].tolist()\n",
    "\n",
    "    print(f\"Generated {len(generated_ids)} tokens\")\n",
    "\n",
    "    # Debug: Check what tokens we got\n",
    "    print(f\"   First 20 tokens: {generated_ids[:20]}\")\n",
    "    print(f\"   Last 20 tokens: {generated_ids[-20:]}\")\n",
    "\n",
    "    # Check if EOS was generated\n",
    "    if CODE_END_TOKEN_ID in generated_ids:\n",
    "        eos_position = generated_ids.index(CODE_END_TOKEN_ID)\n",
    "        print(f\" EOS token found at position {eos_position}/{len(generated_ids)}\")\n",
    "\n",
    "    # Extract SNAC audio tokens\n",
    "    snac_tokens = extract_snac_codes(generated_ids)\n",
    "\n",
    "    print(f\"Extracted {len(snac_tokens)} SNAC tokens\")\n",
    "\n",
    "    # Debug: Analyze token types\n",
    "    snac_count = sum(1 for t in generated_ids if SNAC_MIN_ID <= t <= SNAC_MAX_ID)\n",
    "    other_count = sum(1 for t in generated_ids if t < SNAC_MIN_ID or t > SNAC_MAX_ID)\n",
    "    print(f\"   SNAC tokens in output: {snac_count}\")\n",
    "    print(f\"   Other tokens in output: {other_count}\")\n",
    "\n",
    "    # Check for SOS token\n",
    "    if CODE_START_TOKEN_ID in generated_ids:\n",
    "        sos_pos = generated_ids.index(CODE_START_TOKEN_ID)\n",
    "        print(f\"   SOS token at position: {sos_pos}\")\n",
    "    else:\n",
    "        print(\"   No SOS token found in generated output!\")\n",
    "\n",
    "    if len(snac_tokens) < 7:\n",
    "        print(\"Error: Not enough SNAC tokens generated\")\n",
    "        return\n",
    "\n",
    "    # Unpack SNAC tokens to 3 hierarchical levels\n",
    "    levels = unpack_snac_from_7(snac_tokens)\n",
    "    frames = len(levels[0])\n",
    "\n",
    "    print(f\"Unpacked to {frames} frames\")\n",
    "    print(f\"   L1: {len(levels[0])} codes\")\n",
    "    print(f\"   L2: {len(levels[1])} codes\")\n",
    "    print(f\"   L3: {len(levels[2])} codes\")\n",
    "\n",
    "    # Convert to tensors\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    codes_tensor = [\n",
    "        torch.tensor(level, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        for level in levels\n",
    "    ]\n",
    "\n",
    "    # Generate final audio with SNAC decoder\n",
    "    print(\"Decoding to audio...\")\n",
    "    with torch.inference_mode():\n",
    "        z_q = snac_model.quantizer.from_codes(codes_tensor)\n",
    "        audio = snac_model.decoder(z_q)[0, 0].cpu().numpy()\n",
    "\n",
    "    # Trim warmup samples (first 2048 samples)\n",
    "    if len(audio) > 2048:\n",
    "        audio = audio[2048:]\n",
    "\n",
    "    duration_sec = len(audio) / 24000\n",
    "    print(f\"Audio generated: {len(audio)} samples ({duration_sec:.2f}s)\")\n",
    "\n",
    "    return audio, duration_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6dac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate audio\n",
    "description = \"Realistic male voice in the 30s age with american accent. Normal pitch, warm timbre, conversational pacing.\"\n",
    "text = \"Hello! This is Maya1 <laugh_harder> the best open source voice AI model with emotions.\"\n",
    "\n",
    "audio, duration = generate_speech(description, text)\n",
    "Audio(audio, rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save audio with curent timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"output/output_{timestamp}.wav\"\n",
    "sf.write(output_file, audio, 24000)\n",
    "print(f\"Audio saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
